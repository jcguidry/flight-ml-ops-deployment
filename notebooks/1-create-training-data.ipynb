{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://localhost:8888/tree?token=828ad94db4d7d69d99c8c59436853dc031be47d05fee9a61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SERVICE_ACCOUNT = \"flight-ml-demo-general@aia-ds-accelerator-flight-1.iam.gserviceaccount.com\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_preprocessing.py\n",
    "from datetime import datetime, timedelta\n",
    "import polars as pl\n",
    "from deltalake import DeltaTable\n",
    "import json\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, gcp_client, bucket: str, table_path: str):\n",
    "        self.gcp_client = gcp_client\n",
    "        self.table_path = table_path\n",
    "        self.bucket = bucket\n",
    "        self.table_path_full = f'gs://{bucket}/{table_path}'\n",
    "    \n",
    "    def get_date_from_lookback(self, lookback_days: int, return_as_str = True):\n",
    "        target_date = datetime.utcnow() - timedelta(days=lookback_days)\n",
    "        \n",
    "        if return_as_str:\n",
    "            year, month, day = target_date.year, target_date.month, target_date.day\n",
    "            return f'{year}/{month:02d}/{day:02d}'\n",
    "        else:\n",
    "            return target_date\n",
    "\n",
    "    def read_data(self):\n",
    "        gcp_creds_json_str = json.dumps(self.gcp_client.creds_json)\n",
    "        storage_options = {\"service_account_key\": gcp_creds_json_str}\n",
    "\n",
    "        start_date = self.get_date_from_lookback(lookback_days=365, return_as_str=True)\n",
    "        \n",
    "        df = pl.scan_delta(\n",
    "                self.table_path_full,\n",
    "                pyarrow_options={\"partitions\": [(\"crt_ts_date\", \">=\", start_date)]},\n",
    "                storage_options=storage_options,\n",
    "        )\n",
    "        \n",
    "        print(f\"Data loaded from {self.table_path_full}\")\n",
    "        return df\n",
    "\n",
    "    def create_target(self, df):\n",
    "        # Create target variable, time to landing\n",
    "        landing_times = df.group_by('fa_flight_id').agg(pl.max('actual_in').alias('actual_in_filled'))\n",
    "        df = df.join(landing_times, on='fa_flight_id')\n",
    "        df = df.with_columns( ((pl.col('actual_in_filled').dt.timestamp(\"ms\")-pl.col('event_ts').dt.timestamp(\"ms\"))/1000/60/60 ).alias('target') )\n",
    "        \n",
    "        df = df.sort(['actual_in_filled','crt_ts'])\n",
    "        return df\n",
    "\n",
    "    def remove_incomplete_flights(self, df):\n",
    "        # Remove flights that haven't landed yet\n",
    "        return df.filter( pl.col('actual_in_filled').is_not_null() )\n",
    "\n",
    "    def removed_arrival_events(self, df):\n",
    "        # Arrival events are not useful for training\n",
    "        return df.filter(pl.col('event_type') != 'actual_in')\n",
    "\n",
    "    def process_data(self, df):\n",
    "        df = self.create_target(df)\n",
    "        df = self.remove_incomplete_flights(df)\n",
    "        df = self.removed_arrival_events(df)\n",
    "        return df\n",
    "    \n",
    "    def write_data_to_gcs(self, df, path_out: str):\n",
    "        print(f\"Writing data to {path_out}\")\n",
    "        bucket = self.gcp_client.storage_client.get_bucket(self.bucket) \n",
    "        blob = bucket.blob(f'{path_out}.csv')\n",
    "        blob.upload_from_string(df.collect().to_csv(), 'text/csv')\n",
    "\n",
    "def main():\n",
    "\n",
    "    from gcp import GCPClient\n",
    "\n",
    "    gcp_client = GCPClient()\n",
    "\n",
    "    project_id = 'aia-ds-accelerator-flight-1'\n",
    "    bucket = 'datalake-flight-dev-1'\n",
    "    table_path_in = 'flightsummary-delta-processed-stream'\n",
    "    table_path_out = 'training/flightsummary-training'\n",
    "\n",
    "    data_preprocessor = DataPreprocessor(gcp_client, bucket=bucket, table_path=table_path_in)\n",
    "\n",
    "    # Step 1: Load data\n",
    "    df = data_preprocessor.read_data().collect()\n",
    "\n",
    "    # # Step 2: Process data\n",
    "    df1 = data_preprocessor.process_data(df)\n",
    "\n",
    "    # # Step 3: Write data\n",
    "    data_preprocessor.write_data_to_gcs(df, path_out=table_path_out)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
